[{"content":"For beginners, the writing loop using reduce seems to be confusing at the start, the power of which is yet to be fully unleashed.\n The Good Old For Loop Let\u0026rsquo;s start with a simple calculation of the sum of a number array. All seems natural, it has to have an accumulator, with which an operator + that defines how these numbers can be squashed together one after the other on a loop. Pretty easy right? What if we are asked to do a multiplication of all elements in the array? We would supply a different initial value 1 to the accumulator and a * operator to help us do the heavy lifting work. The rest are being equal, i.e., the structure of the loop and the way we retrieve the current element in the loop.\nconst array = [2, 4, 5, 6]; let accumulation = 0; for (let i = 0; i \u0026lt; array.length; i++) { const element = array[i]; accumulation = accumulation + element; } // accumulation = 17 Reduce, re-introduced The pattern we have discovered tells us to do the reduce, two things need to be defined declaratively:\nüñçÔ∏è The initial value for the accumulator\nüñçÔ∏è The operation that is applied to the accumulation process repeatedly in the loop\nLooking at the signature, that\u0026rsquo;s exactly what reduce method for the array is asking to perform the reducing operation.\nreduce(callbackfn: (previousValue: T, currentValue: T, currentIndex: number, array: T[]) =\u0026gt; T, initialValue: T): T; In the same spirit, one can simply reduce his code to one line by leveraging reduce as follows:\nconst result = [2, 4, 5, 6].reduce( (accumulation, element) =\u0026gt; (accumulation = accumulation + element), 0 ); Notice how we set up the initialValue in the reduce function together with the callbackfn which defines the exact operation we wish to perform on the array.\nReduce in applications One might think that\u0026rsquo;s what reduce can do, with that kind of simplicity. There are many cases where you can apply reduce to solve complex tasks in an elegant way.\nComposition in functions Among them, one could think of a composition of functions, or the decorative pattern in OOP, where complex functionalities are enabled by composing simple, standalone functions together, each of which exposes the same interface.\ninterface Product { price: () =\u0026gt; number; } const createProduct = (value: number): Product =\u0026gt; ({ price: () =\u0026gt; value }); const addPackaging = (product: Product): Product =\u0026gt; ({ price: () =\u0026gt; product.price() + 0.5, }); const addRibons = (product: Product): Product =\u0026gt; ({ price: () =\u0026gt; product.price() + 0.3, }); Considering we have a product whose price is calculated upon the additional services of packaging, to find a product price after applying packaging with ribbons, the final price can be obtained as follows, by supplying the base price of the product:\nconst finalProduct = addRibons(addPackaging(createProduct(20))); Since the composition of functions is nested in nature, it can become difficult to read as those parentheses grow with the addition of functions. Would it be great if one can flatten those nested representations of functions into one single parenthesis? compose comes to the rescue. One can use the pipe or compose from lodash/fp or implement his own pipe function, as this:\nconst pipe = (...fns) =\u0026gt; (x) =\u0026gt; fns.reduce((y, f) =\u0026gt; f(y), x); By leveraging reduce, the array of functions that need to be composed are flattened, while the composition order reversed:\nconst finalProduct = pipe(createProduct, addPackaging, addRibons)(20); One would notice we are composing the functions first and delayed the evaluation to the second call. This pattern of lazy evaluation is of great benefit when dealing with effects, such as I/O events. In JavaScript, we have the Promise helping us reading and writing to the database asynchronously. What would the pipe look like in async fashion?\nAsync Pipe In the case of async, one could think of a consecutive call on an array of promise objects where the precedence matters. And a modification to the implementation of pipe would be as follows:\nconst asyncPipe = (...fns) =\u0026gt; (x) =\u0026gt; fns.reduce(async (y, f) =\u0026gt; f(await y), x); The I/O logic writing imperatively as such:\nasync function ploadFiles({ user, folder, files }) { const dbUser = await readUser({ user }); const folderInfo = await getFolderInfo({ folder }); if (await haveWriteAccess({ dbUser, folderInfo })) { return uploadToFolder({ dbUser, folderInfo, files }); } else { throw new Error(\u0026#34;No write access to that folder\u0026#34;); } } would be rewritten in a much clear and organized way:\nconst uploadFiles = asyncPipe( readUser, getFolderInfo, haveWriteAccess, uploadToFolder ); and calling the uploadFiles in the same fashion:\nuploadFiles({ user, folder, files }).then(log); With the built-in error handling from Promise, the async operation for each step interacting with DB become manageable, and unit testing the operation as a whole becomes the testing of each method, with no dependencies either injected or inherited, which left the only need for integrating testing for uploadFiles itself.\nReduce and Beyond Into the Fantasy Land of Type Theory Equipped with bits of Math, the reducer function can be interpreted as a monoid, a algebraic struture with a single associative binary operation and identity element.\nPut them into mathematical term: \\(S\\bigotimes S \\to S \\), where  üìå Associativity: \\((x\\bigotimes y) \\bigotimes z = x\\bigotimes (y \\bigotimes z)\\)  üìå Identity element: \\(\\exists \\, e \\) in \\(S\\), where \\(e\\bigotimes a = a \\bigotimes e = a\\) holds One could easily recall the instance pair of (‚®Ç, e) in all our previous examples and by induction, approve those operations satisfy the rule of associativity.\nA Transducer Outlook Array.reduce(reducer, initialVal); // reducer manages complex tasks, such as mapping, filtering, etc. // Other than writing in this way of chaining: // Array.filter(...).map(...).reduce(...) // which impact its performance by iterate thru the list multiple times. // We compose the operation of filter and map togerther as the ultimate reducer function. As the role of reducer grows big, to which with multiple individual tasks such as filtering and mapping assigned, it becomes hard to fathom the operation it is conducting. An abstraction of reducer becomes the new transducer, which is left to be done in the future post.êÇÉ\n","permalink":"https://Edwardjia2009.github.io/posts/reduce-in-js/","summary":"\u003cp\u003eFor beginners, the writing loop using \u003ccode\u003ereduce\u003c/code\u003e seems to be confusing at the start, the power of which is yet to be fully unleashed.\u003c/p\u003e\n\u003ch2 id=\"heading\"\u003e\u003c/h2\u003e","title":"Thinking in Reduce"}]